---
title: "McCool_Snake_Project"
author: "Owen McCool, Therese Lamperty"
date: "2024-09-04"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  
```{r package read in}
library(vegan)
library(stringr)
library(ggplot2)
library(tidyverse)
```


# Project Overview

Study Site: Research was split between two different zones within the greater Yasuni Biosphere Reserve. Tiputini Biodiversity Station (TBS) served as the faunally intact site, whereas Yasuni Research Station (YRS) served as the defaunated site. Both sites are situated along the Tiputini River within the province of Orellana, Ecuador. TBS, approximately 45 km east of YRS, is only accessible by boat. YRS is along the Maxus Oil Road, and is less integrated into the Amazonian ecosystem. Additionally, unsustainable hunting activities by the indigenous communities have been prominent in the surrounding region at YRS for multiple decades, as noted from 2014. This is thought to be the root cause of defaunation in this zone. 

	I transferred between the two research stations every two weeks, starting my first rotation at TBS on June 10. Time at each station was spent working on 3 separate projects: my herpetofauna surveys, frugivory surveys, and an overarching seed enemy and dispersal project. 

	The rainy season in Northeastern Ecuador is at its peak between March and July. I conducted my study between the months of June and August, 2024. The average high temperature for June in this region is 85.66° F, with the average low of 70.05° F. July has an average high temperature of 86.29° F and an average low of 69.13° F. August has an average high temperature of 91.35° F and an average low of 69.60° F. June receives 143mm of precipitation on average each year, whereas July receives 99.69mm and August receives 77.55mm. (https://weatherandclimate.com/ecuador/orellana/boca-tiputini) 
Put project description here (field sites, time frame of collection,sampling scheme, type of data (eg. species ID,temp, etc.) )

Surveys: Herpetofauna were sampled using visual surveys on foot by two surveyors/night. Trail systems at each site served as the sampling paths. The surveys were repeated around 6 times on each rotation while in the field, and resampled on the second rotations. The surveys typically began around 20:00-20:30 and lasted until 23:00-00:00 CST. At each site, habitat matches were compared and assessed and trails through that habitat were consistently walked. Two different types of habitat, Terra Firma (uplands) and Varzea (flooded forest) were surveyed on the herp nocturnal walks. In addition to this, two significant bodies of water were also surveyed at each site, primarily consisting of oxbow lakes with one year-round large pond. 

	Surveyors used FENIX HM60R headlamps while conducting night surveys. They carefully examined all surrounding habitat, including understory trees, shrubs, vines, water bodies, forest floor, and middle-canopy. Amphibians of the order Anura gave off reflective eyeshine and were easier to sample for, whereas members of Squamata did not. More information about this will be within the discussion section. Effort hours will be calculated based on survey time length and number of surveyors. 

	Additionally, environmental information was taken throughout the course of each survey. Temperature and humidity data was collected with a Mengshen meter in 30 minute intervals on surveys. Understory vegetation density was also measured every 15 minutes along each trail. A 1.5m PVC pipe was randomly placed upright just off the right side of the trail at each measuring point, and the number of leaves making contact with the pipe was counted. 

	Weather and wind were noted before each survey in four nominal categories, with weather either being “clear, partly cloudy, cloudy, rainy” and wind being “no wind, felt on face, branches move, trees move”. I also accounted for precipitation that had already occurred in 6-hour blocks as “time window of last rain event”. 

	Once an animal was found, the first step of the protocol was to note what time of night the find occurred. After this, the temperature and humidity was once again collected. A rangefinder was used to estimate the perpendicular distance of each animal from the trail. A GPS was used to mark and log the coordinates of each animal found. Animals were given a two-letter code based on the Order and Suborder followed by a number, indicating its position of being found. For example, the code of the 9th snake found of the season would be SK09. Species found were also identified to the lowest taxonomic level in the field, and photographs of individuals were taken both to get positive IDs later in the lab when not possible in the field, but also to avoid counting re-captures.

	Snakes found during non-survey times were also recorded. These individuals were split into one of two categories of detection. The first is an “Opportunistic Encounter” (OE), which is any snake that was found by me while out working on other non-herpetofauna projects in the field. The other type of detection is the Third Party Encounter (TPE). This was any snake that was found by other research groups during my rotations at each station, identified to lowest possible taxonomy. The same data was taken for these individuals. GPS coordinates, time of detection, trail, observer, estimation of distance from trail, and habitat type. Because the third-party observers often didn’t have access to the climate data logger, this information was retrieved later on from each station’s respective weather tower data, based on the time of detection. 

Snakes were given a classification as to whether they were small mammal consumers or not. Information on this was retrieved from literature such as online publications, the book Reptiles and Amphibians of the Amazon by R.D. and Patricia Bartlett, and the expert webpage Reptiles of Ecuador. 

# Analysis

## Prep data

Data preparation: Join snake data collected during standard surveys with the opportunistic/third person data and do some cleaning.

**Note this is commented out and the cleaned and prepped snake data is just read in after the following chunk**

```{r snake data read in and do prelim cleaning}

#snake.sur <- read.csv("snake.sur.csv", na.strings = c("", "NA")) #reading in csv file

#snake.non.sur <- read.csv("snake.non.sur.csv") 

#snake.sur<- snake.sur[-2,] #removing row 2 from UPDATEDsnakes.csv
#colnames(snake.sur) <- snake.sur[1, ] #takes 1st row and makes it column names
#snake.sur <- snake.sur[-1, ] #removed extra row that originally had column names but were now useless
#snake.sur <- snake.sur[ ,-24] #removing column 23


#colnames(snake.non.sur) <- snake.non.sur[1, ] #takes row 1 and makes them column names 
#snake.non.sur <- snake.non.sur[-1, ] #removing first row since it is the same as column names now

# we will now compare column names

#colnames(df.snake.sur)
#colnames(snake.non.sur)

#snake.sur$Species <- trimws(snake.sur$Species)
#snake.non.sur$Species <- trimws(snake.non.sur$Species) #removing trailing spaces

#snake.sur$Species <- str_replace_all(snake.sur$Species, " ", "_") #replaces all spaces w/ underscore

# also get rid of asterisks in dates
#snake.sur$Date <- gsub("\\*", "", snake.sur$Date)

# tell R that the Date column are Dates

#snake.sur$Date <- as.Date(snake.sur$Date, format = "%m/%d/%y")


#snake.non.sur$Date <- as.Date(snake.non.sur$Date, format = "%m/%d/%y")


#snake.non.sur <- snake.non.sur[, -22]

#snake.sur$Obs_type <- "Survey"
#colnames(snake.non.sur)[4] <- "Obs_type"

#colnames(snake.sur)[8] <- "Snake_ID" #changing reptile Id to snake ID

#colnames(snake.sur)[11] <- "Time_Found"

#colnames(snake.sur)[3] <- "Location"
#colnames(snake.non.sur)[3] <- "Location" 

#snake.non.sur$Survey_Start_Time <- NA
#snake.non.sur$Surveyors <- NA
#snake.non.sur$Survey_End_Time <- NA

#colnames(snake.sur)[16] <- "Distance_m"
#colnames(snake.non.sur)[7] <- "During_My_Rotation"

#snake.non.sur$Distance_m <- NA


#snake.sur$During_My_Rotation <- "Yes"

#snake.master <- rbind(snake.non.sur, snake.sur)

#snake.master$Species <- str_replace_all(snake.master$Species, " ", "_") #making sure all snakes have underscored between genus and species

# make a genus column
#snake.master <- snake.master %>%
 # separate(Species, c("Genus", "Species"))
# cases where only genus or family level existed, species column is populated with NA (that's what the warning message is for, can ignore)

#making new master csv, ensuring that extra row names are not added by R
#write.csv(snake.master, "snake.master.csv", row.names = FALSE)
```

```{r read in cleaned and prepped data}
enviro <- read.csv("Environment_Sheet.csv", na.strings = c("", "NA"))

snake.master <- read.csv("snake.master.csv")
```

Begin looking at variation in sampling effort. First, calculate time spend sampling during each night for surveys.

```{r survey samp effort}

# this is only relevant to the snake surveys, to get n hours spent searching
snake.sur <- snake.master %>%
  filter(Obs_type == "Survey")

# first, combine date and time so that you can use 'difftime' to get time elapsed between start and end

snake.sur$Date_Start_Time <- paste(snake.sur$Date, snake.sur$Survey_Start_Time, sep = " ")

#combining end date and time into one column for the full snake dataframe, separated with spaces
# note, R is handeling surveys that lasted past midnight oddly, so we are just using the start Date here as well
snake.sur$Date_End_Time <- paste(snake.sur$Date, snake.sur$Survey_End_Time, sep = " ")

# using difftime to calculate effort hours on each survey
snake.sur$Effort_Hrs <- difftime(snake.sur$Date_End_Time, snake.sur$Date_Start_Time, units = "hours")

```

Now, we want to summarize how many snakes were seen per hour. This is going to involve (1) calculating abundance per survey and then (2) getting a rate of n snakes per hour.

```{r abundance over search effort}

# use dplyr (tidyverse) functions to aggregate the data

temp <- snake.sur %>%
  group_by(Station, Zone, Date, Species, Effort_Hrs) %>%
  tally()

# make an extra column that has the station ID and trail walked and date, separated by //

temp$st.tr.date <- paste(temp$Station, temp$Zone, temp$Date, temp$Effort_Hrs, sep = "//")

# now, let's use dplyr again to transpose (flip) your sp.abun dataframe so that now, you have the species as column names and the number of times they were found at each trail and date will be the data reported (expect lots of 0s and 1s)
temp <- na.omit(temp)

snk.sur.mat <- temp %>% 
  pivot_wider(names_from = Species, 
              values_from = n, 
              values_fill = 0) %>%
  column_to_rownames(var = "st.tr.date")

# cool, now, we need to pull the info out of the row names and make that info columns again. Note, there is probably a better way to do this but here we are. 


snk.sur.mat$st.tr.date <- rownames(snk.sur.mat)

# now you have a column with that whole mess of info
# let's separate the info back out into 3 separate columns
snk.sur.mat <- snk.sur.mat %>% 
  separate(st.tr.date, c('Station', 'Location', 'Date', 'Effort_Hrs'), sep = "//")


# great, let's start getting some info together regarding the abundance, diversity, and species richness of snakes found for each night we did a survey

# get abundance next
snk.sur.mat$total_found <- rowSums(snk.sur.mat[2:18])

# for diversity, we know Simpson's is robust to unbalanced sampling; may change to only using Simpsons. Use function 'diversity' in vegan package, specify the index you want to use (simpson)
snk.sur.mat$simpson_diversity <- diversity(snk.sur.mat[2:18], index = "simpson")

# remove temp df
rm(temp)

# and lets get species richness
snk.sur.mat$richness <- specnumber(snk.sur.mat[2:18])

# at this point, you will want to do a sanity check. Do the data look believable based on what you remember of your time in the field?

# now, get a rate of n snakes obs per hours of searching
snk.sur.mat$total.hr <- (snk.sur.mat$total_found/as.numeric(snk.sur.mat$Effort_Hrs))

# repeat this for richness and diversity (may not use this)
snk.sur.mat$richness.hr <- (snk.sur.mat$richness/as.numeric(snk.sur.mat$Effort_Hrs))

snk.sur.mat$diversity.hr <- (snk.sur.mat$simpson_diversity/as.numeric(snk.sur.mat$Effort_Hrs))

```

Now, get a plot of the detection rates at each hunted and unhunted study area. 

```{r snake plot detection rate}

pooled.detection.plot <- snk.sur.mat %>%
  ggplot(aes(x= Station, y= total.hr, color = Station)) +
  ylab("N snakes found per hour") +
  xlab("") + theme_light() +
  geom_boxplot() + scale_color_manual(values=c("#E69F00", "darkgreen"))

pooled.detection.plot

```
What about snakes found per hour in each feeding guild?

```{r prep to look at feeding guild detections}

# use dplyr (tidyverse) functions to aggregate the data

survey_snake_guilds <- snake.sur %>%
  group_by(Station, Zone, Date, Diet_Type, Effort_Hrs) %>%
  tally()

# make NA's 0s
#survey_snake_guilds <- survey_snake_guilds %>%
 # mutate(n = ifelse(is.na(Diet_Type), 0, n))

# remove NAs
survey_snake_guilds <- na.omit(survey_snake_guilds)

survey_snake_guilds$st.tr.date <- paste(survey_snake_guilds$Station, survey_snake_guilds$Zone, survey_snake_guilds$Date, survey_snake_guilds$Effort_Hrs, sep = "//")


snk.sur.guilds.mat <- survey_snake_guilds %>% 
  pivot_wider(names_from = Diet_Type, 
              values_from = n, 
              values_fill = 0) %>%
  column_to_rownames(var = "st.tr.date")

# cool, now, we need to pull the info out of the row names and make that info columns again. Note, there is probably a better way to do this but here we are. 

snk.sur.guilds.mat$st.tr.date <- rownames(snk.sur.guilds.mat)

# now you have a column with that whole mess of info
# let's separate the info back out into 3 separate columns
snk.sur.guilds.mat <- snk.sur.guilds.mat %>% 
  separate(st.tr.date, c('Station', 'Location', 'Date', 'Effort_Hrs'), sep = "//")


# great, let's start getting some info together regarding the abundance, diversity, and species richness of snakes found for each night we did a survey

# get abundance next
snk.sur.guilds.mat$total_found <- rowSums(snk.sur.mat[2:4])

# now, get a rate of n snakes obs per hours of searching
snk.sur.guilds.mat$total.hr <- (snk.sur.guilds.mat$total_found/as.numeric(snk.sur.guilds.mat$Effort_Hrs))

# transpose

snk.sur.guilds <- snk.sur.guilds %>%
  pivot_longer(total.hr)

snk.sur.guilds <- survey_snake_guilds %>% 
  pivot_longer(names_from = Diet_Type, 
              values_from = n, 
              values_fill = 0) %>%
  column_to_rownames(var = "st.tr.date")
```

```{r plot differences in feeding guild detection rates}

per.guild.detection.plot <- snk.sur.guilds.mat %>%
  ggplot(aes(x= Station, y = total.hr, color = Station)) +
  ylab("N snakes found per hour") + theme_light() +
  geom_boxplot() + scale_color_manual(values=c("#E69F00", "darkgreen"))

per.guild.detection.plot


```
# Next steps: 
- 11/14/24

Look at Jaccard dissimilarity index
1. Add zone from enviro sheet to snake master (match coordinates, make station its own zone)
2. make master df into an occurrence matrix with species as columns
3. separate predictor and visitor variables
4. get jaccard values per date per zone
5. make an NMDS visualization 
 
```{r master snake matrix}

# use dplyr (tidyverse) functions to aggregate the data, now group by station, zone, date, species, use snake.master dataset

occ <- snake.master %>% #need to get snake.master updated to new csv combo
  group_by(Station, Zone, Species) %>%
  tally()

# remove NAs bc they don't tell us anything in this context
occ<-na.omit(occ)

# make an extra column that has the station ID and trail walked and date, separated by //, remove effort hours, location will become 'ZONE'

occ$st.zn.sp <- paste(occ$Station, occ$Zone, occ$Species, sep = "//")

# now, let's use dplyr again to transpose (flip) your sp.abun dataframe so that now, you have the species as column names and the number of times they were found at each trail and date will be the data reported (expect lots of 0s and 1s)

snake.occ.mat <- occ %>% 
  pivot_wider(names_from = Species, #makes the column into the rownames
              values_from = n, 
              values_fill = 0) %>% #will fill spaces with no snakes as 0
  column_to_rownames(var = "st.zn.sp") #will make this new combo the unique identifier as rownames

```

To look at community dissimilarity, we can do a handful of things. Start with computing dissimilarity values based on Jaccard index. This compared presence and absence of species and doesnt tell us much....


``` {r prep predictor and community data}

community <- snake.occ.mat[, c(3:31)] #made matrix from all data columns with n snake data


predictors <- snake.occ.mat[, c(1,2)] #separating non-snake stuff (station and zone)
                          
# remove cases with empty rows, which are 'meaningless' with jaccard. These were the surveys during which we did not find anything. 

Jaccard.dis.mat <- vegdist(community, method = "jaccard") #jaccard only accounts for presence absence 

pnova.jac.sp <- adonis2(Jaccard.dis.mat ~ predictors$Station, method = "jaccard") #adonis looks at specific differences between groups, our group factor is station

# look at results
print(pnova.jac.sp)
```


Bray Curtis index. 0 = totally the same, 1 = totally dissimilar.

In summary, "to calculate Bray-Curtis dissimilarity between two samples, you need to find the sum of the lesser abundances of each species present in both samples, then divide that sum by the total combined abundance of all species in both samples, and finally subtract the result from 1; essentially, it measures the proportion of difference in species abundance between two samples, with a value ranging from 0 (identical samples) to 1 (completely different samples)." 
```{r repeat with bray curtis}
sk.sur <- snk.sur.mat[, c(2:18)] #making matrix of snake observations

groupings <- snk.sur.mat[, c(1, 19)] #making matrix for station and zone

bc.dis.mat <- vegdist(sk.sur, method = "bray")

pnova.bc.sp <- adonis2(bc.dis.mat ~ groupings$Station, method = "bray")

# look at results
print(pnova.bc.sp)
```
"The Morisita and the Horn-Morisita indices measure the probability that individuals drawn one from each vector will belong to different species, relative to drawing from each vector separately. The Morisita index is formulated for count data only, whereas the Horn-Morisita index can be used with transformed counts or proportions."

```{r repeat with horn morisita}

horn.dis.mat <- vegdist(sk.sur, method = "horn")

pnova.horn.sp <- adonis2(horn.dis.mat ~ groupings$Station)

# look at results
print(pnova.horn.sp)
```
```{r nmds visualization with horn}
nmds.horn <- metaMDS(community, distance = "bray", autotransform = TRUE, maxtry = 200)

```


``` {r Owens plots practice }
 OWEN'S EXPERIMENTAL PLOTS 

unique(snake.master$Species)
spec.TBS = unique(snake.master$Species[snake.master$Station == "TBS"])
spec.YRS = unique(snake.master$Species[snake.master$Station == "YRS"])

head(snake.master$Species)

unique_species <- data.frame(Sites = c("YRS", "TBS"),
                             UniqueSpecies = c(length(unique(snake.master$Species[snake.master$Station == "YRS"])),
                                               length(unique(snake.master$Species[snake.master$Station == "TBS"]))))

# figure with number of unique species per site

require(ggplot2)

ggplot(data = unique_species, aes(x = Sites, y = UniqueSpecies)) +
  geom_bar(stat = "identity", fill = c("blue", "green")) +
  xlab("Site ID") +
  ylab("Number of unique species") +
  theme_bw() # theme I like


```



# Get figure set up: boxplot with total/hr from snk.sur.mat, grouped by station, do a kruskal wallis test eventually

``` {r Boxplot for Snake Totals per Hour}

boxplot(snk.sur.mat$total.hr[snk.sur.mat$Station == "TBS"],
        snk.sur.mat$total.hr[snk.sur.mat$Station == "YRS"],
        names = c("TBS", "YRS"), 
        col = c("red", "blue"), 
        xlab = "Station", 
        ylab = "Snakes per Hour",
        main = "Snake Totals per Survey Hours by Station")



```











